{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NeSy4PPM: Multi-attribute (activity and resource) prediction Tutorial\n",
    "This notebook demonstrates how to use the NeSy4PPM framework for multi-attribute suffix prediction, specifically focused on activity and resource prediction using neural architectures like LSTM and Transformer models. NeSy4PPM combines multi-attribute neural predictions with MP-declare BK compliance to produce accurate and compliant predictions under concept drift.\n",
    "\n",
    "This notebook walks through the entire NeSy4PPM pipeline, including:\n",
    "\n",
    "    1. Learning pipeline\n",
    "       1. Data preparation\n",
    "       2. Neural Network training\n",
    "    3. Prediction pipeline"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 1. Learning pipeline\n",
    "The __Learning Pipeline__ is responsible for loading and transforming event log into neural-compatible inputs and training an LSTM or Transformer model to perform next activity and resource prediction. This phase involves both __Prefixes preprocessing__ by extracting and encoding prefixes form training set, and __Neural network training__ that learn to generate the most likely continuations of incomplete process traces."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1.1 Data preparation\n",
    "The first step in the __learning__ pipeline is to load and transform the event log (in a .xes, .csv or .xes.gz files) into a symbolic representation using the `LogData` class, where activity and resource labels are mapped to unique ASCII characters. The input of this step can be:\n",
    "- A __single event log__, which will be automatically split into training and evaluation subsets based on the case start timestamps.\n",
    "- A pair of __separate training and test logs__."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### A. Single event log:"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T12:49:01.179435Z",
     "start_time": "2025-06-18T12:48:59.917573Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "parsing log, completed traces :: 100%|██████████| 4580/4580 [00:00<00:00, 6747.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded log: helpdesk\n",
      "Trace max size: 15\n"
     ]
    }
   ],
   "execution_count": 7,
   "source": [
    "from pathlib import Path\n",
    "from NeSy4PPM.commons import log_utils\n",
    "\n",
    "log_path = Path.cwd().parent/'data'/'input'/'logs'\n",
    "log_name = \"helpdesk.xes\"\n",
    "train_ratio = 0.8\n",
    "case_name_key = 'case:concept:name'\n",
    "act_name_key = 'concept:name'\n",
    "res_name_key = 'org:resource'\n",
    "timestamp_key = 'time:timestamp'\n",
    "\n",
    "log_data = log_utils.LogData(log_path=log_path,log_name=log_name,train_ratio=train_ratio,\n",
    "                             case_name_key=case_name_key,act_name_key=act_name_key,\n",
    "                             res_name_key=res_name_key,timestamp_key=timestamp_key,resource=True)\n",
    "print(f\"Loaded log: {log_data.log_name}\")\n",
    "print(f\"Trace max size: {log_data.max_len}\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### B. Separate training and test logs:"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T15:18:13.103287Z",
     "start_time": "2025-06-18T15:18:11.776509Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "parsing log, completed traces :: 100%|██████████| 3664/3664 [00:00<00:00, 5120.82it/s]\n",
      "parsing log, completed traces :: 100%|██████████| 820/820 [00:00<00:00, 6406.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded log: helpdesk_train\n",
      "Trace max size: 15\n"
     ]
    }
   ],
   "execution_count": 2,
   "source": [
    "from pathlib import Path\n",
    "from NeSy4PPM.commons import log_utils\n",
    "\n",
    "log_path = Path.cwd().parent/'data'/'input'/'logs'\n",
    "train_log = \"helpdesk_train.xes\"\n",
    "test_log = \"helpdesk_test.xes\"\n",
    "\n",
    "log_data = log_utils.LogData(log_path=log_path,train_log=train_log,test_log=test_log,resource=True)\n",
    "print(f\"Loaded log: {log_data.log_name}\")\n",
    "print(f\"Trace max size: {log_data.max_len}\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2.2 Prefixes preprocessing\n",
    "The `Prefixes preprocessing` step extracts prefixes (i.e., partial traces executions) from the training log and encodes them into numerical representations suitable for neural models. This can be done by calling `extract_trace_prefixes` and `encode_prefixes` for extracting and encoding prefixes, respectively or only by calling `extract_encode_prefixes` function."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Step 1: Prefixes extraction\n",
    "The `extract_trace_prefixes` function extracts all possible prefixes from each trace in the training log, up to a predefined maximum length. These prefixes represent partial executions of cases and are used as inputs to the neural model."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T14:01:14.375810Z",
     "start_time": "2025-06-18T14:01:14.109750Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from NeSy4PPM.learning.prefixes_preprocessing import extract_trace_prefixes\n",
    "\n",
    "extracted_prefixes = extract_trace_prefixes(log_data=log_data, resource=True)"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Step 2: Prefixes encodings\n",
    "Before training a neural model, extracted prefixes must be converted into vectorized formats. NeSy4PPM supports four encoding techniques for multi-attribute: \n",
    "- `One-hot encoding`,\n",
    "- `Index-based encoding`,\n",
    "- `Shrinked index-based encoding`, \n",
    "- `Multi-encoders encoding`.\n",
    "\n",
    "Each encoding is implemented via the function `encode_prefixes` and prepares both input features (`x`) and two targets labels: `y_a` for activity prediction and `y_g` for resource prediction."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### One-hot encoding\n",
    "In the __One-hot encoding__, sequences of events are converted into high-dimensional binary feature vectors. Each feature corresponds to a concatenation of one-hot encoded activity and resource values derived from the log. To apply index-based encoding, set the `encoder` parameter to `Encodings.One_hot` when calling the `encode_prefixes` function:"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T14:01:19.394934Z",
     "start_time": "2025-06-18T14:01:19.191158Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from NeSy4PPM.learning.prefixes_preprocessing import encode_prefixes\n",
    "from NeSy4PPM.commons.utils import Encodings\n",
    "\n",
    "x, y_a, y_g= encode_prefixes(log_data,prefixes=extracted_prefixes,encoder=Encodings.One_hot,resource=True)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total resources: 22 - Target resources: 23\n",
      "\t ['Value 2', 'Value 5', 'Value 16', 'Value 15', 'Value 21', 'Value 10', 'Value 11', 'Value 12', 'Value 6', 'Value 7', 'Value 9', 'Value 14', 'Value 19', 'Value 17', 'Value 8', 'Value 13', 'Value 22', 'Value 1', 'Value 4', 'Value 3', 'Value 18', 'Value 20']\n",
      "Total activities: 14 - Target activities: 15\n",
      "\t ['Assign seriousness', 'Take in charge ticket', 'Resolve ticket', 'Closed', 'Wait', 'Create SW anomaly', 'Insert ticket', 'Schedule intervention', 'INVALID', 'RESOLVED', 'VERIFIED', 'Resolve SW anomaly', 'Require upgrade', 'DUPLICATE']\n",
      "Num. of learning sequences: 16937\n",
      "Encoding...\n",
      "Num. of features: 36\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Index-based encoding\n",
    "In the __Index-based encoding__, sequences of events are transformed into numerical feature vectors, where each event is represented by a pair of indices: one for the activity and one for the resource. These indices correspond to the positions of the activity and resource in their respective predefined sets. To apply index-based encoding, set the `encoder` parameter to `Encodings.Index_based` when calling the `encode_prefixes` function:"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T14:01:26.914596Z",
     "start_time": "2025-06-18T14:01:26.712254Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from NeSy4PPM.learning.prefixes_preprocessing import encode_prefixes\n",
    "from NeSy4PPM.commons.utils import Encodings\n",
    "\n",
    "x, y_a, y_g = encode_prefixes(log_data,prefixes=extracted_prefixes, encoder=Encodings.Index_based,resource=True)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total resources: 22 - Target resources: 23\n",
      "\t ['Value 2', 'Value 5', 'Value 16', 'Value 15', 'Value 21', 'Value 10', 'Value 11', 'Value 12', 'Value 6', 'Value 7', 'Value 9', 'Value 14', 'Value 19', 'Value 17', 'Value 8', 'Value 13', 'Value 22', 'Value 1', 'Value 4', 'Value 3', 'Value 18', 'Value 20']\n",
      "Total activities: 14 - Target activities: 15\n",
      "\t ['Assign seriousness', 'Take in charge ticket', 'Resolve ticket', 'Closed', 'Wait', 'Create SW anomaly', 'Insert ticket', 'Schedule intervention', 'INVALID', 'RESOLVED', 'VERIFIED', 'Resolve SW anomaly', 'Require upgrade', 'DUPLICATE']\n",
      "Num. of learning sequences: 16937\n",
      "Encoding...\n",
      "Num. of features: 30\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Shrinked index-based encoding\n",
    "In the __Shrinked index-based encoding__, sequences of events are transformed into numerical feature vectors by assigning a unique integer index to each activity–resource pair. To apply shrinked index-based encoding, set the encoder parameter to `Encodings.Shrinked_based` when calling the `encode_prefixes` function:"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T14:01:32.281594Z",
     "start_time": "2025-06-18T14:01:32.075937Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from NeSy4PPM.learning.prefixes_preprocessing import encode_prefixes\n",
    "from NeSy4PPM.commons.utils import Encodings\n",
    "\n",
    "x, y_a, y_g = encode_prefixes(log_data,prefixes=extracted_prefixes, encoder=Encodings.Shrinked_based, resource=True)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total resources: 22 - Target resources: 23\n",
      "\t ['Value 2', 'Value 5', 'Value 16', 'Value 15', 'Value 21', 'Value 10', 'Value 11', 'Value 12', 'Value 6', 'Value 7', 'Value 9', 'Value 14', 'Value 19', 'Value 17', 'Value 8', 'Value 13', 'Value 22', 'Value 1', 'Value 4', 'Value 3', 'Value 18', 'Value 20']\n",
      "Total activities: 14 - Target activities: 15\n",
      "\t ['Assign seriousness', 'Take in charge ticket', 'Resolve ticket', 'Closed', 'Wait', 'Create SW anomaly', 'Insert ticket', 'Schedule intervention', 'INVALID', 'RESOLVED', 'VERIFIED', 'Resolve SW anomaly', 'Require upgrade', 'DUPLICATE']\n",
      "Num. of learning sequences: 16937\n",
      "Encoding...\n",
      "Num. of features: 15\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Multi-encoders encoding\n",
    "In the __Multi-encoders encoding__, sequences of events are represented using separate embedding spaces for activities and resources. Each activity and resource is first embedded independently, and then enriched with cross-information using a modulation mechanism that captures their interactions. The final representation combines the modulated embeddings using learned alignment weights. To apply multi-encoders encoding, set the encoder parameter to `Encodings.Multi_encoders` when calling the `encode_prefixes` function:"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T14:01:38.519172Z",
     "start_time": "2025-06-18T14:01:38.328192Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from NeSy4PPM.learning.prefixes_preprocessing import encode_prefixes\n",
    "from NeSy4PPM.commons.utils import Encodings\n",
    "\n",
    "x, y_a, y_g = encode_prefixes(log_data,prefixes=extracted_prefixes, encoder=Encodings.Multi_encoders, resource=True)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total resources: 22 - Target resources: 23\n",
      "\t ['Value 2', 'Value 5', 'Value 16', 'Value 15', 'Value 21', 'Value 10', 'Value 11', 'Value 12', 'Value 6', 'Value 7', 'Value 9', 'Value 14', 'Value 19', 'Value 17', 'Value 8', 'Value 13', 'Value 22', 'Value 1', 'Value 4', 'Value 3', 'Value 18', 'Value 20']\n",
      "Total activities: 14 - Target activities: 15\n",
      "\t ['Assign seriousness', 'Take in charge ticket', 'Resolve ticket', 'Closed', 'Wait', 'Create SW anomaly', 'Insert ticket', 'Schedule intervention', 'INVALID', 'RESOLVED', 'VERIFIED', 'Resolve SW anomaly', 'Require upgrade', 'DUPLICATE']\n",
      "Num. of learning sequences: 16937\n",
      "Encoding...\n",
      "Num. of features: 15\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Steps 1&2: End-to-end prefixes preprocessing"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T15:19:49.602088Z",
     "start_time": "2025-06-18T15:19:49.119263Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from NeSy4PPM.learning.prefixes_preprocessing import extract_encode_prefixes\n",
    "from NeSy4PPM.commons.utils import Encodings\n",
    "\n",
    "encoder = Encodings.Index_based\n",
    "x, y_a, y_g = extract_encode_prefixes(log_data, encoder=encoder, resource=True)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total resources: 22 - Target resources: 23\n",
      "\t ['Value 2', 'Value 5', 'Value 16', 'Value 15', 'Value 21', 'Value 10', 'Value 11', 'Value 12', 'Value 6', 'Value 7', 'Value 9', 'Value 14', 'Value 19', 'Value 17', 'Value 8', 'Value 13', 'Value 22', 'Value 1', 'Value 4', 'Value 3', 'Value 18', 'Value 20']\n",
      "Total activities: 14 - Target activities: 15\n",
      "\t ['Assign seriousness', 'Take in charge ticket', 'Resolve ticket', 'Closed', 'Wait', 'Create SW anomaly', 'Insert ticket', 'Schedule intervention', 'INVALID', 'RESOLVED', 'VERIFIED', 'Resolve SW anomaly', 'Require upgrade', 'DUPLICATE']\n",
      "Num. of learning sequences: 16937\n",
      "Encoding...\n",
      "Num. of features: 30\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1.2 Neural Network training\n",
    "Once the prefixes are encoded, NeSy4PPM proceeds to train a neural network that learns to predict the next activity and resource given a partial trace. The training is handled via the `train` function, which takes the encoded prefix data (`x`, `y_a`, `y_g`) and builds a model according to the chosen architecture. NeSy4PPM supports two neural architectures:\n",
    "\n",
    "- __LSTM (Long Short-Term Memory)__ networks, which are recurrent neural networks designed to handle sequential data with long-range dependencies. To use LSTM, set the `model_arch` parameter to `NN_model.LSTM`.\n",
    "- __Transformer__ architectures, which use attention mechanisms to model relationships across all positions in the prefix sequence simultaneously. To use a Transformer, set the `model_arch` parameter to `NN_model.Transformer`."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from NeSy4PPM.learning.train_model import train\n",
    "from NeSy4PPM.commons.utils import NN_model\n",
    "\n",
    "model = NN_model.Transformer\n",
    "model_folder= Path.cwd().parent/'data'/'output'\n",
    "train(log_data, encoder, model_arch=model, output_folder=model_folder, x=x, y_a=y_a, y_g=y_g)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 2. Prediction pipeline\n",
    "The __Prediction Pipeline__ in NeSy4PPM is responsible for generating multi-attribute (activity and resource) suffix predictions from a prefix (i.e., an incomplete trace) using a trained neural model. To enhance both accuracy and compliance under concept drift, it supports two main prediction modes:\n",
    "- __BK-contextualized Beam Search__: the BK is used *during* beam search to guide which branches are explored based on compliance.\n",
    "- __BK-based Filtering__: the BK is used *after* the beam search to filter out non-compliant predicted suffixes.\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3.1 Set prediction parameters\n",
    "The prediction process begins by specifying the following parameters that control how the prediction algorithm operates:\n",
    "- `log_data.evaluation_prefix_start`: the minimum prefix length (in events) for prediction.\n",
    "- `log_data.evaluation_prefix_end`: the maximum prefix length for prediction.\n",
    "- `model_arch`: the trained model architecture (`NN_model.LSTM` or `NN_model.Transformer`).\n",
    "- `encoder`: the encoding method used during training (`Encodings.One_hot`, `Encodings.Index_based`, `Encodings.Shrinked_index_based` or `Encodings.Multi_Encoders` ).\n",
    "- `output_folder`: the path where the trained model and prediction results are saved.\n",
    "- `bk_file_path`: the path to the `BK` (background knowledge) file.\n",
    "- `beam_size`: the number of alternative suffixes explored in parallel by the beam search. A `simple autoregressive prediction` can be performed by setting `beam_size` to `0` (greedy search).\n",
    "- `weight`: a float value in [0, 1] that balances the importance of neural predictions and BK compliance. A value of 0 uses only the neural model, while higher values increase the importance of BK during the search.\n",
    "- `BK_end`: a boolean parameter indicating whether BK is applied at the end (i.e., filtering) instead of during the search.\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T15:20:10.905132Z",
     "start_time": "2025-06-18T15:20:10.889501Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from NeSy4PPM.commons.utils import NN_model\n",
    "from NeSy4PPM.commons.utils import Encodings\n",
    "\n",
    "(log_data.evaluation_prefix_start, log_data.evaluation_prefix_end) = (1,4)\n",
    "model_arch = NN_model.Transformer\n",
    "encoder = Encodings.Index_based\n",
    "output_folder= Path.cwd().parent/'data'/'output'\n",
    "bk_file_path = Path.cwd().parent/'data'/'input'/'declare_models'/'BK_helpdesk.decl'\n",
    "beam_size = 3\n",
    "weight = [0.9]\n",
    "BK_end = False"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2.2 Load the Background Knowledge (BK)\n",
    "After setting the parameters, a background knowledge (BK) model must be loaded using the `load_bk` function. For multi-attribute prediction, only MP-declare models (`.decl`) are supported."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T15:20:13.324697Z",
     "start_time": "2025-06-18T15:20:13.293445Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from NeSy4PPM.commons.utils import load_bk\n",
    "\n",
    "bk_model = load_bk(bk_file_path)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Existence1[Closed] |A.org:resource is Value 3 |\n",
      "1 Chain Precedence[Resolve ticket, Closed] |A.org:resource is Value 3 | |\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2.3 Perform Prediction\n",
    "NeSy4PPM implements the `predict_evaluate` function, which generates activity-resource suffixes using the proposed neuro-symbolic beam search algorithm and computes two evaluation metrics:\n",
    "   - __Damerau-Levenshtein Similarity__, measuring the similarity between the predicted and actual suffixes based on edit distance,\n",
    "   - __Jaccard Similarity__, measuring the overlap between the sets of predicted and actual activities. suffix prediction using a trained neural model and loaded `BK` model.\n",
    "\n",
    "By default, this function operates on the __entire test log__, predicting suffixes for all traces defined in the test set."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "## Entire test log prediction\n",
    "from NeSy4PPM.prediction import evaluation\n",
    "\n",
    "evaluation.predict_evaluate(log_data, model_arch=model_arch, encoder=encoder,\n",
    "                            output_folder=output_folder, bk_model=bk_model, beam_size=beam_size, resource=True, weight=weight, bk_end=BK_end)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "However, `predict_evaluate` function can also be used to predict suffixes for a specific __subset of traces__ by providing a list of case IDs from the test log."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T14:15:05.549867Z",
     "start_time": "2025-06-18T14:14:29.693549Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## A subset of test log prediction\n",
    "from NeSy4PPM.prediction import evaluation\n",
    "traces_ids = ['Case 1327']\n",
    "evaluation.predict_evaluate(log_data, model_arch=model_arch, encoder=encoder,evaluation_trace_ids= traces_ids,\n",
    "                            output_folder=output_folder, bk_model=bk_model, beam_size=beam_size, resource=True, weight=weight, bk_end=BK_end)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:h5py._conv:Creating converter from 3 to 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0 - Activity & Resource Prediction\n",
      "Model filepath: C:\\Users\\JOukharijane\\Desktop\\PostDoc\\NeSy4PPM\\docs\\source\\data\\output\\keras_trans_index-based\\0\\models\\CFR\\helpdesk_train\n",
      "Latest checkpoint file: C:\\Users\\JOukharijane\\Desktop\\PostDoc\\NeSy4PPM\\docs\\source\\data\\output\\keras_trans_index-based\\0\\models\\CFR\\helpdesk_train\\model_024-1.193.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JOukharijane\\AppData\\Local\\Programs\\Python\\Python310\\lib\\random.py:370: DeprecationWarning: non-integer arguments to randrange() have been deprecated since Python 3.10 and will be removed in a subsequent version\n",
      "  return self.randrange(a, b+1)\n",
      "C:\\Users\\JOukharijane\\AppData\\Local\\Programs\\Python\\Python310\\lib\\random.py:370: DeprecationWarning: non-integer arguments to randrange() have been deprecated since Python 3.10 and will be removed in a subsequent version\n",
      "  return self.randrange(a, b+1)\n",
      "C:\\Users\\JOukharijane\\AppData\\Local\\Programs\\Python\\Python310\\lib\\random.py:370: DeprecationWarning: non-integer arguments to randrange() have been deprecated since Python 3.10 and will be removed in a subsequent version\n",
      "  return self.randrange(a, b+1)\n",
      "C:\\Users\\JOukharijane\\AppData\\Local\\Programs\\Python\\Python310\\lib\\random.py:370: DeprecationWarning: non-integer arguments to randrange() have been deprecated since Python 3.10 and will be removed in a subsequent version\n",
      "  return self.randrange(a, b+1)\n",
      "C:\\Users\\JOukharijane\\AppData\\Local\\Programs\\Python\\Python310\\lib\\random.py:370: DeprecationWarning: non-integer arguments to randrange() have been deprecated since Python 3.10 and will be removed in a subsequent version\n",
      "  return self.randrange(a, b+1)\n",
      "C:\\Users\\JOukharijane\\AppData\\Local\\Programs\\Python\\Python310\\lib\\random.py:370: DeprecationWarning: non-integer arguments to randrange() have been deprecated since Python 3.10 and will be removed in a subsequent version\n",
      "  return self.randrange(a, b+1)\n",
      "C:\\Users\\JOukharijane\\AppData\\Local\\Programs\\Python\\Python310\\lib\\random.py:370: DeprecationWarning: non-integer arguments to randrange() have been deprecated since Python 3.10 and will be removed in a subsequent version\n",
      "  return self.randrange(a, b+1)\n",
      "C:\\Users\\JOukharijane\\AppData\\Local\\Programs\\Python\\Python310\\lib\\random.py:370: DeprecationWarning: non-integer arguments to randrange() have been deprecated since Python 3.10 and will be removed in a subsequent version\n",
      "  return self.randrange(a, b+1)\n",
      "C:\\Users\\JOukharijane\\AppData\\Local\\Programs\\Python\\Python310\\lib\\random.py:370: DeprecationWarning: non-integer arguments to randrange() have been deprecated since Python 3.10 and will be removed in a subsequent version\n",
      "  return self.randrange(a, b+1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Case ID', 'Prefix length', 'Trace Prefix Act', 'Ground truth', 'Predicted Acts', 'Damerau-Levenshtein Acts', 'Jaccard Acts', 'Trace Prefix Res', 'Ground Truth Resources', 'Predicted Resources', 'Damerau-Levenshtein Resources', 'Jaccard Resources', 'Damerau-Levenshtein Combined', 'Weight']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\JOukharijane\\Desktop\\PostDoc\\NeSy4PPM\\venv\\lib\\site-packages\\tqdm\\std.py:917: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return getattr(df, df_function)(wrapper, **kwargs)\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Case 1327', 1, 'Assign seriousness', 'Wait, Resolve ticket, Closed', 'Take in charge ticket, Resolve ticket, Closed', 0.6666666666666667, 0.5, 'Value 13', 'Value 1, Value 13, Value 3', 'Value 13, Value 13, Value 3', 0.6666666666666667, 0.6666666666666666, 0.6666666666666667, 0.9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\JOukharijane\\Desktop\\PostDoc\\NeSy4PPM\\venv\\lib\\site-packages\\tqdm\\std.py:917: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return getattr(df, df_function)(wrapper, **kwargs)\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Case 1327', 2, 'Assign seriousness, Wait', 'Resolve ticket, Closed', 'Resolve ticket, Closed', 1.0, 1.0, 'Value 13, Value 1', 'Value 13, Value 3', 'Value 1, Value 3', 0.5, 0.33333333333333326, 0.75, 0.9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\JOukharijane\\Desktop\\PostDoc\\NeSy4PPM\\venv\\lib\\site-packages\\tqdm\\std.py:917: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return getattr(df, df_function)(wrapper, **kwargs)\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Case 1327', 3, 'Assign seriousness, Wait, Resolve ticket', 'Closed', 'Closed', 1.0, 1.0, 'Value 13, Value 1, Value 13', 'Value 3', 'Value 3', 1.0, 1.0, 1.0, 0.9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\JOukharijane\\Desktop\\PostDoc\\NeSy4PPM\\venv\\lib\\site-packages\\tqdm\\std.py:917: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return getattr(df, df_function)(wrapper, **kwargs)\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "C:\\Users\\JOukharijane\\AppData\\Local\\Programs\\Python\\Python310\\lib\\random.py:370: DeprecationWarning: non-integer arguments to randrange() have been deprecated since Python 3.10 and will be removed in a subsequent version\n",
      "  return self.randrange(a, b+1)\n",
      "C:\\Users\\JOukharijane\\AppData\\Local\\Programs\\Python\\Python310\\lib\\random.py:370: DeprecationWarning: non-integer arguments to randrange() have been deprecated since Python 3.10 and will be removed in a subsequent version\n",
      "  return self.randrange(a, b+1)\n",
      "C:\\Users\\JOukharijane\\AppData\\Local\\Programs\\Python\\Python310\\lib\\random.py:370: DeprecationWarning: non-integer arguments to randrange() have been deprecated since Python 3.10 and will be removed in a subsequent version\n",
      "  return self.randrange(a, b+1)\n",
      "C:\\Users\\JOukharijane\\AppData\\Local\\Programs\\Python\\Python310\\lib\\random.py:370: DeprecationWarning: non-integer arguments to randrange() have been deprecated since Python 3.10 and will be removed in a subsequent version\n",
      "  return self.randrange(a, b+1)\n",
      "C:\\Users\\JOukharijane\\AppData\\Local\\Programs\\Python\\Python310\\lib\\random.py:370: DeprecationWarning: non-integer arguments to randrange() have been deprecated since Python 3.10 and will be removed in a subsequent version\n",
      "  return self.randrange(a, b+1)\n",
      "C:\\Users\\JOukharijane\\AppData\\Local\\Programs\\Python\\Python310\\lib\\random.py:370: DeprecationWarning: non-integer arguments to randrange() have been deprecated since Python 3.10 and will be removed in a subsequent version\n",
      "  return self.randrange(a, b+1)\n",
      "C:\\Users\\JOukharijane\\AppData\\Local\\Programs\\Python\\Python310\\lib\\random.py:370: DeprecationWarning: non-integer arguments to randrange() have been deprecated since Python 3.10 and will be removed in a subsequent version\n",
      "  return self.randrange(a, b+1)\n",
      "C:\\Users\\JOukharijane\\AppData\\Local\\Programs\\Python\\Python310\\lib\\random.py:370: DeprecationWarning: non-integer arguments to randrange() have been deprecated since Python 3.10 and will be removed in a subsequent version\n",
      "  return self.randrange(a, b+1)\n",
      "C:\\Users\\JOukharijane\\AppData\\Local\\Programs\\Python\\Python310\\lib\\random.py:370: DeprecationWarning: non-integer arguments to randrange() have been deprecated since Python 3.10 and will be removed in a subsequent version\n",
      "  return self.randrange(a, b+1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME TO FINISH --- 12.620225429534912 seconds ---\n",
      "fold 1 - Activity & Resource Prediction\n",
      "Model filepath: C:\\Users\\JOukharijane\\Desktop\\PostDoc\\NeSy4PPM\\docs\\source\\data\\output\\keras_trans_index-based\\1\\models\\CFR\\helpdesk_train\n",
      "Latest checkpoint file: C:\\Users\\JOukharijane\\Desktop\\PostDoc\\NeSy4PPM\\docs\\source\\data\\output\\keras_trans_index-based\\1\\models\\CFR\\helpdesk_train\\model_014-1.198.keras\n",
      "['Case ID', 'Prefix length', 'Trace Prefix Act', 'Ground truth', 'Predicted Acts', 'Damerau-Levenshtein Acts', 'Jaccard Acts', 'Trace Prefix Res', 'Ground Truth Resources', 'Predicted Resources', 'Damerau-Levenshtein Resources', 'Jaccard Resources', 'Damerau-Levenshtein Combined', 'Weight']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\JOukharijane\\Desktop\\PostDoc\\NeSy4PPM\\venv\\lib\\site-packages\\tqdm\\std.py:917: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return getattr(df, df_function)(wrapper, **kwargs)\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Case 1327', 1, 'Assign seriousness', 'Wait, Resolve ticket, Closed', 'Take in charge ticket, Resolve ticket, Closed', 0.6666666666666667, 0.5, 'Value 13', 'Value 1, Value 13, Value 3', 'Value 13, Value 13, Value 3', 0.6666666666666667, 0.6666666666666666, 0.6666666666666667, 0.9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\JOukharijane\\Desktop\\PostDoc\\NeSy4PPM\\venv\\lib\\site-packages\\tqdm\\std.py:917: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return getattr(df, df_function)(wrapper, **kwargs)\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Case 1327', 2, 'Assign seriousness, Wait', 'Resolve ticket, Closed', 'Resolve ticket, Closed', 1.0, 1.0, 'Value 13, Value 1', 'Value 13, Value 3', 'Value 2, Value 3', 0.5, 0.33333333333333326, 0.75, 0.9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\JOukharijane\\Desktop\\PostDoc\\NeSy4PPM\\venv\\lib\\site-packages\\tqdm\\std.py:917: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return getattr(df, df_function)(wrapper, **kwargs)\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Case 1327', 3, 'Assign seriousness, Wait, Resolve ticket', 'Closed', 'Closed', 1.0, 1.0, 'Value 13, Value 1, Value 13', 'Value 3', 'Value 3', 1.0, 1.0, 1.0, 0.9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\JOukharijane\\Desktop\\PostDoc\\NeSy4PPM\\venv\\lib\\site-packages\\tqdm\\std.py:917: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return getattr(df, df_function)(wrapper, **kwargs)\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "C:\\Users\\JOukharijane\\AppData\\Local\\Programs\\Python\\Python310\\lib\\random.py:370: DeprecationWarning: non-integer arguments to randrange() have been deprecated since Python 3.10 and will be removed in a subsequent version\n",
      "  return self.randrange(a, b+1)\n",
      "C:\\Users\\JOukharijane\\AppData\\Local\\Programs\\Python\\Python310\\lib\\random.py:370: DeprecationWarning: non-integer arguments to randrange() have been deprecated since Python 3.10 and will be removed in a subsequent version\n",
      "  return self.randrange(a, b+1)\n",
      "C:\\Users\\JOukharijane\\AppData\\Local\\Programs\\Python\\Python310\\lib\\random.py:370: DeprecationWarning: non-integer arguments to randrange() have been deprecated since Python 3.10 and will be removed in a subsequent version\n",
      "  return self.randrange(a, b+1)\n",
      "C:\\Users\\JOukharijane\\AppData\\Local\\Programs\\Python\\Python310\\lib\\random.py:370: DeprecationWarning: non-integer arguments to randrange() have been deprecated since Python 3.10 and will be removed in a subsequent version\n",
      "  return self.randrange(a, b+1)\n",
      "C:\\Users\\JOukharijane\\AppData\\Local\\Programs\\Python\\Python310\\lib\\random.py:370: DeprecationWarning: non-integer arguments to randrange() have been deprecated since Python 3.10 and will be removed in a subsequent version\n",
      "  return self.randrange(a, b+1)\n",
      "C:\\Users\\JOukharijane\\AppData\\Local\\Programs\\Python\\Python310\\lib\\random.py:370: DeprecationWarning: non-integer arguments to randrange() have been deprecated since Python 3.10 and will be removed in a subsequent version\n",
      "  return self.randrange(a, b+1)\n",
      "C:\\Users\\JOukharijane\\AppData\\Local\\Programs\\Python\\Python310\\lib\\random.py:370: DeprecationWarning: non-integer arguments to randrange() have been deprecated since Python 3.10 and will be removed in a subsequent version\n",
      "  return self.randrange(a, b+1)\n",
      "C:\\Users\\JOukharijane\\AppData\\Local\\Programs\\Python\\Python310\\lib\\random.py:370: DeprecationWarning: non-integer arguments to randrange() have been deprecated since Python 3.10 and will be removed in a subsequent version\n",
      "  return self.randrange(a, b+1)\n",
      "C:\\Users\\JOukharijane\\AppData\\Local\\Programs\\Python\\Python310\\lib\\random.py:370: DeprecationWarning: non-integer arguments to randrange() have been deprecated since Python 3.10 and will be removed in a subsequent version\n",
      "  return self.randrange(a, b+1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME TO FINISH --- 24.26862668991089 seconds ---\n",
      "fold 2 - Activity & Resource Prediction\n",
      "Model filepath: C:\\Users\\JOukharijane\\Desktop\\PostDoc\\NeSy4PPM\\docs\\source\\data\\output\\keras_trans_index-based\\2\\models\\CFR\\helpdesk_train\n",
      "Latest checkpoint file: C:\\Users\\JOukharijane\\Desktop\\PostDoc\\NeSy4PPM\\docs\\source\\data\\output\\keras_trans_index-based\\2\\models\\CFR\\helpdesk_train\\model_022-1.191.keras\n",
      "['Case ID', 'Prefix length', 'Trace Prefix Act', 'Ground truth', 'Predicted Acts', 'Damerau-Levenshtein Acts', 'Jaccard Acts', 'Trace Prefix Res', 'Ground Truth Resources', 'Predicted Resources', 'Damerau-Levenshtein Resources', 'Jaccard Resources', 'Damerau-Levenshtein Combined', 'Weight']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\JOukharijane\\Desktop\\PostDoc\\NeSy4PPM\\venv\\lib\\site-packages\\tqdm\\std.py:917: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return getattr(df, df_function)(wrapper, **kwargs)\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Case 1327', 1, 'Assign seriousness', 'Wait, Resolve ticket, Closed', 'Take in charge ticket, Resolve ticket, Closed', 0.6666666666666667, 0.5, 'Value 13', 'Value 1, Value 13, Value 3', 'Value 13, Value 13, Value 3', 0.6666666666666667, 0.6666666666666666, 0.6666666666666667, 0.9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\JOukharijane\\Desktop\\PostDoc\\NeSy4PPM\\venv\\lib\\site-packages\\tqdm\\std.py:917: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return getattr(df, df_function)(wrapper, **kwargs)\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Case 1327', 2, 'Assign seriousness, Wait', 'Resolve ticket, Closed', 'Resolve ticket, Closed', 1.0, 1.0, 'Value 13, Value 1', 'Value 13, Value 3', 'Value 1, Value 3', 0.5, 0.33333333333333326, 0.75, 0.9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\JOukharijane\\Desktop\\PostDoc\\NeSy4PPM\\venv\\lib\\site-packages\\tqdm\\std.py:917: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return getattr(df, df_function)(wrapper, **kwargs)\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Case 1327', 3, 'Assign seriousness, Wait, Resolve ticket', 'Closed', 'Closed', 1.0, 1.0, 'Value 13, Value 1, Value 13', 'Value 3', 'Value 3', 1.0, 1.0, 1.0, 0.9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\JOukharijane\\Desktop\\PostDoc\\NeSy4PPM\\venv\\lib\\site-packages\\tqdm\\std.py:917: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return getattr(df, df_function)(wrapper, **kwargs)\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME TO FINISH --- 35.831690311431885 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "9b13726099ff4a9270d97cd5a303046c40236cea9d4b3d3acf7f22861afad882"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
