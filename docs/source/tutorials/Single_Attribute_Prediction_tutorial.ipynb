{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NeSy4PPM: Single-attribute (activity) prediction Tutorial\n",
    "This notebook demonstrates how to use the NeSy4PPM framework for single-attribute suffix prediction, specifically focused on activity prediction using neural architectures like LSTM and Transformer models. NeSy4PPM combines neural learning with symbolic background knowledge (BK) to produce accurate and compliant predictions under various conditions, including concept drift.\n",
    "\n",
    "This notebook guides you through the full NeSy4PPM pipeline, including::\n",
    "\n",
    "    1. Data preparation\n",
    "    2. Learning pipeline\n",
    "       1. Prefixes preprocessing\n",
    "       2. Neural Network training\n",
    "    3. Prediction pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data preparation\n",
    "The first step in the NeSy4PPM pipeline is to load and transform the event log (in a `.xes`, `.csv` or `.xes.gz` format) into a symbolic representation using the `LogData` class, where activity labels are mapped to unique ASCII characters. Depending on the input configuration, the log can be:\n",
    "- A __single event log__, which will be automatically split into training and test subsets based on the case start timestamps.\n",
    "- A pair of __separate training and test logs__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## A. Single event log:"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T12:58:31.815147Z",
     "start_time": "2025-06-18T12:58:30.732975Z"
    }
   },
   "source": [
    "from pathlib import Path\n",
    "from NeSy4PPM.commons import log_utils\n",
    "log_path = Path.cwd().parent/'data'/'input'/'logs'\n",
    "log_name = \"helpdesk.xes\"\n",
    "train_ratio = 0.8\n",
    "case_name_key = 'case:concept:name'\n",
    "act_name_key = 'concept:name'\n",
    "timestamp_key = 'time:timestamp'\n",
    "\n",
    "log_data = log_utils.LogData(log_path=log_path,log_name=log_name,train_ratio=train_ratio,\n",
    "                             case_name_key=case_name_key,act_name_key=act_name_key,\n",
    "                             timestamp_key=timestamp_key,resource=False)\n",
    "print(f\"Loaded log: {log_data.log_name}\")\n",
    "print(f\"Trace max size: {log_data.max_len}\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "parsing log, completed traces :: 100%|██████████| 4580/4580 [00:00<00:00, 7500.51it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded log: helpdesk\n",
      "Trace max size: 15\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## B. Separate training and test logs:"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T14:29:08.937084Z",
     "start_time": "2025-06-18T14:29:08.103465Z"
    }
   },
   "source": [
    "from pathlib import Path\n",
    "from NeSy4PPM.commons import log_utils\n",
    "log_path = Path.cwd().parent/'data'/'input'/'logs'\n",
    "train_log = \"helpdesk_train.xes\"\n",
    "test_log = \"helpdesk_filtred.xes\"\n",
    "\n",
    "log_data = log_utils.LogData(log_path=log_path,train_log=train_log,test_log=test_log)\n",
    "print(f\"Loaded log: {log_data.log_name}\")\n",
    "print(f\"Trace max size: {log_data.max_len}\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "parsing log, completed traces :: 100%|██████████| 3664/3664 [00:00<00:00, 9148.38it/s]\n",
      "parsing log, completed traces :: 100%|██████████| 320/320 [00:00<00:00, 10232.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded log: helpdesk_train\n",
      "Trace max size: 15\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Learning pipeline\n",
    "The __Learning Pipeline__ is responsible for transforming symbolic traces into neural-compatible inputs and training an LSTM or Transformer model to perform next activity prediction. This phase involves both __Prefixes preprocessing__ by extracting and encoding prefixes form training set, and __Neural network training__ that learn to generate the most likely continuations of incomplete process traces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Prefixes preprocessing\n",
    "The `Prefixes preprocessing` step extracts prefixes (i.e., partial traces executions) from the training log and encodes them into numerical representations suitable for neural models. This can be done by calling `extract_trace_prefixes` and `encode_prefixes` for extracting and encoding prefixes, respectively or only by calling `extract_encode_prefixes` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Prefixes extraction\n",
    "The `extract_trace_prefixes` function extracts all possible prefixes from each trace in the training log, up to a predefined maximum length. These prefixes represent partial executions of cases and are used as inputs to the neural model."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T14:04:40.012836Z",
     "start_time": "2025-06-18T14:04:39.812585Z"
    }
   },
   "source": [
    "from NeSy4PPM.learning.prefixes_preprocessing import extract_trace_prefixes\n",
    "\n",
    "extracted_prefixes = extract_trace_prefixes(log_data=log_data)"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Prefixes encodings\n",
    "To enable deep learning, extracted prefixes must be converted into vectorized formats. NeSy4PPM supports two encoding techniques for single attribute: (i) `One-hot` and (ii) `Index-based` encodings. Each encoding is implemented via the function `encode_prefixes` and prepares both input features (`x`) and target labels `y_a` for activity prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One-hot encoding\n",
    "In __One-hot encoding__, sequences of events are converted into high-dimensional binary feature vectors. Each feature corresponds to a one-hot encoded activity values derived from the log. This encoding can be applied by setting the `encoder` parameter to `Encodings.One_hot` in the `encode_prefixes` function:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T14:04:52.787340Z",
     "start_time": "2025-06-18T14:04:52.678049Z"
    }
   },
   "source": [
    "from NeSy4PPM.learning.prefixes_preprocessing import encode_prefixes\n",
    "from NeSy4PPM.commons.utils import Encodings\n",
    "\n",
    "x, y_a, target_res= encode_prefixes(log_data,prefixes=extracted_prefixes,encoder=Encodings.One_hot)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total activities: 13 - Target activities: 14\n",
      "\t ['Assign seriousness', 'Take in charge ticket', 'Resolve ticket', 'Closed', 'Wait', 'Create SW anomaly', 'Insert ticket', 'Schedule intervention', 'INVALID', 'RESOLVED', 'VERIFIED', 'Resolve SW anomaly', 'Require upgrade']\n",
      "Num. of learning sequences: 16937\n",
      "Num. of features: 14\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Index-based encoding\n",
    "In __Index-based encoding__, sequences of events are transformed into numerical feature vectors. Each event is represented by an integer index that corresponds to the position of the activity in the predefined activity set. To apply index-based encoding, set the `encoder` parameter to `Encodings.Index_based` when calling the `encode_prefixes` function:\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T14:04:56.216909Z",
     "start_time": "2025-06-18T14:04:56.122034Z"
    }
   },
   "source": [
    "from NeSy4PPM.learning.prefixes_preprocessing import encode_prefixes\n",
    "from NeSy4PPM.commons.utils import Encodings\n",
    "\n",
    "x, y_a, _ = encode_prefixes(log_data,prefixes=extracted_prefixes, encoder=Encodings.Index_based)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total activities: 13 - Target activities: 14\n",
      "\t ['Assign seriousness', 'Take in charge ticket', 'Resolve ticket', 'Closed', 'Wait', 'Create SW anomaly', 'Insert ticket', 'Schedule intervention', 'INVALID', 'RESOLVED', 'VERIFIED', 'Resolve SW anomaly', 'Require upgrade']\n",
      "Num. of learning sequences: 16937\n",
      "Num. of features: 15\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Steps 1&2: End-to-End Prefixes preprocessing"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T14:29:46.299002Z",
     "start_time": "2025-06-18T14:29:46.042497Z"
    }
   },
   "source": [
    "from NeSy4PPM.learning.prefixes_preprocessing import extract_encode_prefixes\n",
    "from NeSy4PPM.commons.utils import Encodings\n",
    "\n",
    "encoder = Encodings.Index_based\n",
    "x, y_a, _ = extract_encode_prefixes(log_data, encoder=encoder)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total activities: 13 - Target activities: 14\n",
      "\t ['Assign seriousness', 'Take in charge ticket', 'Resolve ticket', 'Closed', 'Wait', 'Create SW anomaly', 'Insert ticket', 'Schedule intervention', 'INVALID', 'RESOLVED', 'VERIFIED', 'Resolve SW anomaly', 'Require upgrade']\n",
      "Num. of learning sequences: 16937\n",
      "Num. of features: 15\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Neural Network training\n",
    "Once the prefixes are encoded, NeSy4PPM proceeds to train a neural network that learns to predict the next activity given a partial trace. The training is handled via the `train` function, which takes the encoded prefix data (`x`, `y_a`) and builds a model according to the chosen architecture. NeSy4PPM supports two neural architectures:\n",
    "\n",
    "- __LSTM (Long Short-Term Memory)__ networks, which are recurrent neural networks designed to handle sequential data with long-range dependencies. To use LSTM, set the `model_arch` parameter to `NN_model.LSTM`.\n",
    "- __Transformer__ architectures, which use attention mechanisms to model relationships across all positions in the prefix sequence simultaneously. To use a Transformer, set the `model_arch` parameter to `NN_model.Transformer`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from NeSy4PPM.learning.train_model import train\n",
    "from NeSy4PPM.commons.utils import NN_model\n",
    "\n",
    "model = NN_model.Transformer\n",
    "model_folder= Path.cwd().parent/'data'/'output'\n",
    "train(log_data, encoder, model_arch=model, output_folder=model_folder, x=x, y_a=y_a)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Prediction Pipeline\n",
    "\n",
    "The __Prediction Pipeline__ in NeSy4PPM is responsible for generating activity suffix predictions from a prefix (i.e., an incomplete trace) using a trained neural model. To enhance both accuracy and compliance under concept drift, it supports two main prediction modes:\n",
    "- __BK-contextualized Beam Search__: the BK is used *during* beam search to guide which branches are explored based on compliance.\n",
    "- __BK-based Filtering__: the BK is used *after* the beam search to filter out non-compliant predicted suffixes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Set prediction parameters\n",
    "The prediction process begins by specifying the following parameters that control how the prediction algorithm operates:\n",
    "- `log_data.evaluation_prefix_start`: the minimum prefix length (in events) for prediction.\n",
    "- `log_data.evaluation_prefix_end`: the maximum prefix length for prediction.\n",
    "- `model_arch`: the trained model architecture (`NN_model.LSTM` or `NN_model.Transformer`).\n",
    "- `encoder`: the encoding method used during training (`Encodings.One_hot` or `Encodings.Index_based`).\n",
    "- `output_folder`: the path where the trained model and prediction results are saved.\n",
    "- `bk_file_path`: the path to the `BK` (background knowledge) file.\n",
    "- `beam_size`: the number of alternative suffixes explored in parallel by the beam search. A `simple autoregressive prediction` can be performed by setting `beam_size` to `0` (greedy search).\n",
    "- `weight`: a float value in [0, 1] that balances the importance of neural predictions and BK compliance. A value of 0 uses only the neural model, while higher values increase the importance of BK during the search.\n",
    "- `BK_end`: a boolean parameter indicating whether BK is applied at the end (i.e., filtering) instead of during the search,\n",
    "- `fitness_method`: the method used to compute compliance scores—i.e., the alignment or replay fitness between the predicted trace and the procedural model. This parameter is only applicable when the BK model is procedural, and must be set to one of the following: : `conformance_diagnostics_alignments`, `fitness_alignments`, `conformance_diagnostics_token_based_replay` or `fitness_token_based_replay`.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T14:30:48.501843Z",
     "start_time": "2025-06-18T14:30:48.473622Z"
    }
   },
   "source": [
    "from NeSy4PPM.commons.utils import NN_model\n",
    "from NeSy4PPM.commons.utils import Encodings\n",
    "\n",
    "(log_data.evaluation_prefix_start, log_data.evaluation_prefix_end) = (1,4)\n",
    "model_arch = NN_model.Transformer\n",
    "encoder = Encodings.Index_based\n",
    "output_folder= Path.cwd().parent/'data'/'output'\n",
    "bk_file_path = Path.cwd().parent/'data'/'input'/'declare_models'/'BK_helpdesk_filtred.decl'\n",
    "beam_size = 3\n",
    "weight = [0.9]\n",
    "BK_end = False"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Load the Background Knowledge (BK)\n",
    "After setting the parameters, a background knowledge (BK) model must be loaded using the `load_bk` function. `BK` can represent domain constraints or business rules, and can be encoded in various formats:\n",
    "\n",
    "- __Procedural models__: `.bpmn` (Business Process Model and Notation), `.pnml` (Petri Nets)\n",
    "- __Declare models__: `.decl` (Declare constraints)\n",
    "- __Probabilistic Declare models__: `.txt` (Declare constraints annotated with probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T14:30:51.422112Z",
     "start_time": "2025-06-18T14:30:51.406489Z"
    }
   },
   "source": [
    "from NeSy4PPM.commons.utils import load_bk\n",
    "\n",
    "bk_model = load_bk(bk_file_path)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Alternate Precedence[Wait, Closed] | | |\n",
      "1 Alternate Response[Assign seriousness, Wait] | | |\n",
      "2 Alternate Precedence[Wait, Resolve ticket] | | |\n",
      "3 Exactly1[Wait] | |\n",
      "4 Chain Response[Take in charge ticket, Wait] | | |\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Perform Prediction\n",
    "NeSy4PPM implements the `predict_evaluate` function, which generates activity suffixes using the proposed neuro-symbolic beam search algorithm and computes two evaluation metrics:\n",
    "   - __Damerau-Levenshtein Similarity__, measuring the similarity between the predicted and actual suffixes based on edit distance,\n",
    "   - __Jaccard Similarity__, measuring the overlap between the sets of predicted and actual activities. suffix prediction using a trained neural model and loaded `BK` model.\n",
    "\n",
    "By default, this function operates on the __entire test log__, predicting suffixes for all traces defined in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Entire test log prediction\n",
    "from NeSy4PPM.prediction import evaluation\n",
    "\n",
    "evaluation.predict_evaluate(log_data, model_arch=model_arch, encoder=encoder,\n",
    "                            output_folder=output_folder, bk_model=bk_model, beam_size=beam_size, weight=weight)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "However, `predict_evaluate` function can also be used to predict suffixes for a specific __subset of traces__ by providing a list of case IDs from the test log."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T14:31:16.093082Z",
     "start_time": "2025-06-18T14:31:10.844312Z"
    }
   },
   "cell_type": "code",
   "source": [
    "### A subset of test log prediction\n",
    "from NeSy4PPM.prediction import evaluation\n",
    "traces_ids = ['Case 1327']\n",
    "evaluation.predict_evaluate(log_data, model_arch=model_arch, encoder=encoder,evaluation_trace_ids= traces_ids,\n",
    "                            output_folder=output_folder, bk_model=bk_model, beam_size=beam_size, weight=weight)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:h5py._conv:Creating converter from 3 to 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0 - Activity Prediction\n",
      "Model filepath: C:\\Users\\JOukharijane\\Desktop\\PostDoc\\NeSy4PPM\\docs\\source\\data\\output\\keras_trans_index-based\\0\\models\\CF\\helpdesk_train\n",
      "Latest checkpoint file: C:\\Users\\JOukharijane\\Desktop\\PostDoc\\NeSy4PPM\\docs\\source\\data\\output\\keras_trans_index-based\\0\\models\\CF\\helpdesk_train\\model_020-0.424.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JOukharijane\\AppData\\Local\\Programs\\Python\\Python310\\lib\\random.py:370: DeprecationWarning: non-integer arguments to randrange() have been deprecated since Python 3.10 and will be removed in a subsequent version\n",
      "  return self.randrange(a, b+1)\n",
      "C:\\Users\\JOukharijane\\AppData\\Local\\Programs\\Python\\Python310\\lib\\random.py:370: DeprecationWarning: non-integer arguments to randrange() have been deprecated since Python 3.10 and will be removed in a subsequent version\n",
      "  return self.randrange(a, b+1)\n",
      "C:\\Users\\JOukharijane\\AppData\\Local\\Programs\\Python\\Python310\\lib\\random.py:370: DeprecationWarning: non-integer arguments to randrange() have been deprecated since Python 3.10 and will be removed in a subsequent version\n",
      "  return self.randrange(a, b+1)\n",
      "C:\\Users\\JOukharijane\\AppData\\Local\\Programs\\Python\\Python310\\lib\\random.py:370: DeprecationWarning: non-integer arguments to randrange() have been deprecated since Python 3.10 and will be removed in a subsequent version\n",
      "  return self.randrange(a, b+1)\n",
      "C:\\Users\\JOukharijane\\AppData\\Local\\Programs\\Python\\Python310\\lib\\random.py:370: DeprecationWarning: non-integer arguments to randrange() have been deprecated since Python 3.10 and will be removed in a subsequent version\n",
      "  return self.randrange(a, b+1)\n",
      "C:\\Users\\JOukharijane\\AppData\\Local\\Programs\\Python\\Python310\\lib\\random.py:370: DeprecationWarning: non-integer arguments to randrange() have been deprecated since Python 3.10 and will be removed in a subsequent version\n",
      "  return self.randrange(a, b+1)\n",
      "C:\\Users\\JOukharijane\\AppData\\Local\\Programs\\Python\\Python310\\lib\\random.py:370: DeprecationWarning: non-integer arguments to randrange() have been deprecated since Python 3.10 and will be removed in a subsequent version\n",
      "  return self.randrange(a, b+1)\n",
      "C:\\Users\\JOukharijane\\AppData\\Local\\Programs\\Python\\Python310\\lib\\random.py:370: DeprecationWarning: non-integer arguments to randrange() have been deprecated since Python 3.10 and will be removed in a subsequent version\n",
      "  return self.randrange(a, b+1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Case ID', 'Prefix length', 'Trace Prefix Act', 'Ground truth', 'Predicted', 'Damerau-Levenshtein', 'Jaccard', 'Weight']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\JOukharijane\\Desktop\\PostDoc\\NeSy4PPM\\venv\\lib\\site-packages\\tqdm\\std.py:917: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return getattr(df, df_function)(wrapper, **kwargs)\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Case 1327', 1, 'Assign seriousness', 'Wait, Resolve ticket, Closed', 'Wait, Resolve ticket, Closed', 1.0, 1.0, 0.9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\JOukharijane\\Desktop\\PostDoc\\NeSy4PPM\\venv\\lib\\site-packages\\tqdm\\std.py:917: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return getattr(df, df_function)(wrapper, **kwargs)\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Case 1327', 2, 'Assign seriousness, Wait', 'Resolve ticket, Closed', 'Resolve ticket, Closed', 1.0, 1.0, 0.9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\JOukharijane\\Desktop\\PostDoc\\NeSy4PPM\\venv\\lib\\site-packages\\tqdm\\std.py:917: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return getattr(df, df_function)(wrapper, **kwargs)\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Case 1327', 3, 'Assign seriousness, Wait, Resolve ticket', 'Closed', 'Closed', 1.0, 1.0, 0.9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\JOukharijane\\Desktop\\PostDoc\\NeSy4PPM\\venv\\lib\\site-packages\\tqdm\\std.py:917: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return getattr(df, df_function)(wrapper, **kwargs)\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "C:\\Users\\JOukharijane\\AppData\\Local\\Programs\\Python\\Python310\\lib\\random.py:370: DeprecationWarning: non-integer arguments to randrange() have been deprecated since Python 3.10 and will be removed in a subsequent version\n",
      "  return self.randrange(a, b+1)\n",
      "C:\\Users\\JOukharijane\\AppData\\Local\\Programs\\Python\\Python310\\lib\\random.py:370: DeprecationWarning: non-integer arguments to randrange() have been deprecated since Python 3.10 and will be removed in a subsequent version\n",
      "  return self.randrange(a, b+1)\n",
      "C:\\Users\\JOukharijane\\AppData\\Local\\Programs\\Python\\Python310\\lib\\random.py:370: DeprecationWarning: non-integer arguments to randrange() have been deprecated since Python 3.10 and will be removed in a subsequent version\n",
      "  return self.randrange(a, b+1)\n",
      "C:\\Users\\JOukharijane\\AppData\\Local\\Programs\\Python\\Python310\\lib\\random.py:370: DeprecationWarning: non-integer arguments to randrange() have been deprecated since Python 3.10 and will be removed in a subsequent version\n",
      "  return self.randrange(a, b+1)\n",
      "C:\\Users\\JOukharijane\\AppData\\Local\\Programs\\Python\\Python310\\lib\\random.py:370: DeprecationWarning: non-integer arguments to randrange() have been deprecated since Python 3.10 and will be removed in a subsequent version\n",
      "  return self.randrange(a, b+1)\n",
      "C:\\Users\\JOukharijane\\AppData\\Local\\Programs\\Python\\Python310\\lib\\random.py:370: DeprecationWarning: non-integer arguments to randrange() have been deprecated since Python 3.10 and will be removed in a subsequent version\n",
      "  return self.randrange(a, b+1)\n",
      "C:\\Users\\JOukharijane\\AppData\\Local\\Programs\\Python\\Python310\\lib\\random.py:370: DeprecationWarning: non-integer arguments to randrange() have been deprecated since Python 3.10 and will be removed in a subsequent version\n",
      "  return self.randrange(a, b+1)\n",
      "C:\\Users\\JOukharijane\\AppData\\Local\\Programs\\Python\\Python310\\lib\\random.py:370: DeprecationWarning: non-integer arguments to randrange() have been deprecated since Python 3.10 and will be removed in a subsequent version\n",
      "  return self.randrange(a, b+1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME TO FINISH --- 2.2968838214874268 seconds ---\n",
      "fold 1 - Activity Prediction\n",
      "Model filepath: C:\\Users\\JOukharijane\\Desktop\\PostDoc\\NeSy4PPM\\docs\\source\\data\\output\\keras_trans_index-based\\1\\models\\CF\\helpdesk_train\n",
      "Latest checkpoint file: C:\\Users\\JOukharijane\\Desktop\\PostDoc\\NeSy4PPM\\docs\\source\\data\\output\\keras_trans_index-based\\1\\models\\CF\\helpdesk_train\\model_022-0.424.keras\n",
      "['Case ID', 'Prefix length', 'Trace Prefix Act', 'Ground truth', 'Predicted', 'Damerau-Levenshtein', 'Jaccard', 'Weight']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\JOukharijane\\Desktop\\PostDoc\\NeSy4PPM\\venv\\lib\\site-packages\\tqdm\\std.py:917: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return getattr(df, df_function)(wrapper, **kwargs)\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Case 1327', 1, 'Assign seriousness', 'Wait, Resolve ticket, Closed', 'Wait, Resolve ticket, Closed', 1.0, 1.0, 0.9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\JOukharijane\\Desktop\\PostDoc\\NeSy4PPM\\venv\\lib\\site-packages\\tqdm\\std.py:917: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return getattr(df, df_function)(wrapper, **kwargs)\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Case 1327', 2, 'Assign seriousness, Wait', 'Resolve ticket, Closed', 'Resolve ticket, Closed', 1.0, 1.0, 0.9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Case 1327', 3, 'Assign seriousness, Wait, Resolve ticket', 'Closed', 'Closed', 1.0, 1.0, 0.9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JOukharijane\\Desktop\\PostDoc\\NeSy4PPM\\venv\\lib\\site-packages\\tqdm\\std.py:917: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return getattr(df, df_function)(wrapper, **kwargs)\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.30it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\JOukharijane\\Desktop\\PostDoc\\NeSy4PPM\\venv\\lib\\site-packages\\tqdm\\std.py:917: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return getattr(df, df_function)(wrapper, **kwargs)\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "C:\\Users\\JOukharijane\\AppData\\Local\\Programs\\Python\\Python310\\lib\\random.py:370: DeprecationWarning: non-integer arguments to randrange() have been deprecated since Python 3.10 and will be removed in a subsequent version\n",
      "  return self.randrange(a, b+1)\n",
      "C:\\Users\\JOukharijane\\AppData\\Local\\Programs\\Python\\Python310\\lib\\random.py:370: DeprecationWarning: non-integer arguments to randrange() have been deprecated since Python 3.10 and will be removed in a subsequent version\n",
      "  return self.randrange(a, b+1)\n",
      "C:\\Users\\JOukharijane\\AppData\\Local\\Programs\\Python\\Python310\\lib\\random.py:370: DeprecationWarning: non-integer arguments to randrange() have been deprecated since Python 3.10 and will be removed in a subsequent version\n",
      "  return self.randrange(a, b+1)\n",
      "C:\\Users\\JOukharijane\\AppData\\Local\\Programs\\Python\\Python310\\lib\\random.py:370: DeprecationWarning: non-integer arguments to randrange() have been deprecated since Python 3.10 and will be removed in a subsequent version\n",
      "  return self.randrange(a, b+1)\n",
      "C:\\Users\\JOukharijane\\AppData\\Local\\Programs\\Python\\Python310\\lib\\random.py:370: DeprecationWarning: non-integer arguments to randrange() have been deprecated since Python 3.10 and will be removed in a subsequent version\n",
      "  return self.randrange(a, b+1)\n",
      "C:\\Users\\JOukharijane\\AppData\\Local\\Programs\\Python\\Python310\\lib\\random.py:370: DeprecationWarning: non-integer arguments to randrange() have been deprecated since Python 3.10 and will be removed in a subsequent version\n",
      "  return self.randrange(a, b+1)\n",
      "C:\\Users\\JOukharijane\\AppData\\Local\\Programs\\Python\\Python310\\lib\\random.py:370: DeprecationWarning: non-integer arguments to randrange() have been deprecated since Python 3.10 and will be removed in a subsequent version\n",
      "  return self.randrange(a, b+1)\n",
      "C:\\Users\\JOukharijane\\AppData\\Local\\Programs\\Python\\Python310\\lib\\random.py:370: DeprecationWarning: non-integer arguments to randrange() have been deprecated since Python 3.10 and will be removed in a subsequent version\n",
      "  return self.randrange(a, b+1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME TO FINISH --- 3.8046345710754395 seconds ---\n",
      "fold 2 - Activity Prediction\n",
      "Model filepath: C:\\Users\\JOukharijane\\Desktop\\PostDoc\\NeSy4PPM\\docs\\source\\data\\output\\keras_trans_index-based\\2\\models\\CF\\helpdesk_train\n",
      "Latest checkpoint file: C:\\Users\\JOukharijane\\Desktop\\PostDoc\\NeSy4PPM\\docs\\source\\data\\output\\keras_trans_index-based\\2\\models\\CF\\helpdesk_train\\model_021-0.423.keras\n",
      "['Case ID', 'Prefix length', 'Trace Prefix Act', 'Ground truth', 'Predicted', 'Damerau-Levenshtein', 'Jaccard', 'Weight']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\JOukharijane\\Desktop\\PostDoc\\NeSy4PPM\\venv\\lib\\site-packages\\tqdm\\std.py:917: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return getattr(df, df_function)(wrapper, **kwargs)\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Case 1327', 1, 'Assign seriousness', 'Wait, Resolve ticket, Closed', 'Wait, Resolve ticket, Closed', 1.0, 1.0, 0.9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\JOukharijane\\Desktop\\PostDoc\\NeSy4PPM\\venv\\lib\\site-packages\\tqdm\\std.py:917: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return getattr(df, df_function)(wrapper, **kwargs)\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Case 1327', 2, 'Assign seriousness, Wait', 'Resolve ticket, Closed', 'Resolve ticket, Closed', 1.0, 1.0, 0.9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Case 1327', 3, 'Assign seriousness, Wait, Resolve ticket', 'Closed', 'Closed', 1.0, 1.0, 0.9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JOukharijane\\Desktop\\PostDoc\\NeSy4PPM\\venv\\lib\\site-packages\\tqdm\\std.py:917: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return getattr(df, df_function)(wrapper, **kwargs)\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.25it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\JOukharijane\\Desktop\\PostDoc\\NeSy4PPM\\venv\\lib\\site-packages\\tqdm\\std.py:917: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return getattr(df, df_function)(wrapper, **kwargs)\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME TO FINISH --- 5.233134746551514 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "9b13726099ff4a9270d97cd5a303046c40236cea9d4b3d3acf7f22861afad882"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
